{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transposed Convolutions\n",
    "The CNN layers we have seen so far, such as convolutional layers and pooling layers typically reduce (downsample) the spatial dimensions (height and width) of the input, or keep them unchanged.\n",
    "\n",
    "In semantic segmentation that classifies at pixel-level, it will be convenient if the spatial dimensions of the input and output are the same. For example, the channel dimension at one output pixel can hold the classification results for the input pixel at the same spatial position.\n",
    "\n",
    "To achieve this, especially after the spatial dimensions are reduced by CNN layers, we can use another type of CNN layers that can increase (upsample) the spatial dimensions of intermediate feature maps.\n",
    "\n",
    "In this section, we will introduce transposed convolution, which is also called fractionally-strided convolution, for reversing downsampling operations by the convolution."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Operations\n",
    "Ignoring channels for now, letâ€™s begin with the basic transposed convolution operation with stride of 1 and no padding.\n",
    "\n",
    "\n",
    "Suppose that we are given a $n_h \\times n_w$ input tensor and a $k_h \\times k_w$ kernel. Sliding the kernel window with stride of 1 for $n_w$ times in each row\n",
    "and $n_h$ times in each column yields a total of $n_h n_w$ intermediate results. Each intermediate result is a $(n_h + k_h - 1) \\times (n_w + k_w - 1)$ tensor that are initialized as zeros\n",
    "\n",
    "<img src='img_1.png'>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def trans_conv(X_in, Kernel):\n",
    "    h, w = Kernel.shape\n",
    "    Y = torch.zeros(X_in.shape[0] + h -1, X_in.shape[1] + w -1)\n",
    "    for i in range(X_in.shape[0]):\n",
    "        for j in range(X_in.shape[1]):\n",
    "            Y[i: i + h, j: j + w] += X_in[i,j] * Kernel\n",
    "    return Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.,  0.,  1.],\n        [ 0.,  4.,  6.],\n        [ 4., 12.,  9.]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "trans_conv(X, K)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 2])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, when the input X and kernel K are both four-dimensional tensors, we can use high-level APIs to obtain the same results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 0.,  0.,  1.],\n          [ 0.,  4.,  6.],\n          [ 4., 12.,  9.]]]], grad_fn=<ConvolutionBackward0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import ConvTranspose2d\n",
    "X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2)\n",
    "tconv = ConvTranspose2d(1, 1, kernel_size=2, bias=False)\n",
    "tconv.weight.data = K\n",
    "tconv(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Padding, Strides, and Multiple Channels\n",
    "\n",
    "Different from in the regular convolution where padding is applied to input, **it is applied to output in the transposed convolution**.\n",
    "\n",
    "For example, when specifying the padding number on either side of the height and width as 1:\n",
    "* The first and last rows and columns will be removed from the transposed convolution output.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[1.1750]]]], grad_fn=<ConvolutionBackward0>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tconv = ConvTranspose2d(1, 1, kernel_size=2, padding=1, bias=False)\n",
    "tconv(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[[4.]]]], grad_fn=<ConvolutionBackward0>)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tconv.weight.data = K\n",
    "print(tconv(X).shape)\n",
    "tconv(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src='img_2.png'>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**In the transposed convolution, strides are specified for intermediate results (thus output), not for input**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 4, 4])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tconv = ConvTranspose2d(1, 1, kernel_size=2, stride=2,  bias=False)\n",
    "tconv(X).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 3, 3])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tconv = ConvTranspose2d(1, 1, kernel_size=2, stride=1,  bias=False)\n",
    "tconv(X).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 3, 3])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tconv = ConvTranspose2d(1, 1, kernel_size=2, stride=1,  bias=False)\n",
    "tconv(X).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For multiple input and output channels, the transposed convolution works in the same way as the regular convolution.\n",
    "\n",
    "Suppose that the input has $c_i$ channels, and that the transposed convolution assigns a $k_h \\ * \\ k_w $ kernel tensor to each input channel. When multiple output channels are specified, we will have a $c_i * \\ k_h \\ * \\ k_w $ kernel for each output channel."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As in all, if we feed $\\mathsf{X}$ into a convolutional layer $f$ to output $\\mathsf{Y}=f(\\mathsf{X})$ and create a transposed convolutional layer $g$ with the same hyperparameters as $f$ except for the number of output channels being the number of channels in $\\mathsf{X}$, then $g(Y)$ will have the same shape as $\\mathsf{X}$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 10, 16, 16])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Conv2d\n",
    "X = torch.randn(1, 10 , 16, 16)\n",
    "conv = Conv2d(10 , 20, kernel_size=5, padding=2, stride=3)\n",
    "tconv = ConvTranspose2d(20, 10, kernel_size=5, padding=2, stride=3)\n",
    "tconv(conv(X)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 20, 6, 6])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(X).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 10, 14, 14])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = Conv2d(10 , 20, kernel_size=3, padding=2, stride=3)\n",
    "tconv = ConvTranspose2d(20, 10, kernel_size=3, padding=2, stride=3)\n",
    "tconv(conv(X)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Connection to Matrix Transposition\n",
    "The transposed convolution is named after the matrix transposition."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[27., 37.],\n        [57., 67.]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from d2l import torch as d2l\n",
    "X = torch.arange(9.0).reshape(3, 3)\n",
    "K = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "Y = d2l.corr2d(X, K)\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 2., 0., 3., 4., 0., 0., 0., 0.],\n        [0., 1., 2., 0., 3., 4., 0., 0., 0.],\n        [0., 0., 0., 1., 2., 0., 3., 4., 0.],\n        [0., 0., 0., 0., 1., 2., 0., 3., 4.]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kernel2matrix(K):\n",
    "    k, W = torch.zeros(5), torch.zeros((4, 9))\n",
    "    k[:2], k[3:5] = K[0, :], K[1, :]\n",
    "    W[0, :5], W[1, 1:6], W[2, 3:8], W[3, 4:] = k, k, k, k\n",
    "    return W\n",
    "\n",
    "W = kernel2matrix(K)\n",
    "W"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[True, True],\n        [True, True]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y == torch.matmul(W, X.reshape(-1)).reshape(2, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Likewise, we can implement transposed convolutions using matrix multiplications"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[True, True, True],\n        [True, True, True],\n        [True, True, True]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = trans_conv(Y, K)\n",
    "Z == torch.matmul(W.T, Y.reshape(-1)).reshape(3, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Consider implementing the convolution by multiplying matrices. Given an input vector $\\mathbf{x}$ and a weight matrix $\\mathbf{W}$, the forward propagation function of the convolution can be implemented by multiplying its input with the weight matrix and outputting a vector $\\mathbf{y}=\\mathbf{W}\\mathbf{x}$. Since backpropagation\n",
    "follows the chain rule and $\\nabla_{\\mathbf{x}}\\mathbf{y}=\\mathbf{W}^\\top$, the backpropagation function of the convolution can be implemented by multiplying its input with the transposed weight matrix $\\mathbf{W}^\\top$. Therefore, the transposed convolutional layer can just exchange the forward propagation function and the backpropagation function of the convolutional layer: its forward propagation and backpropagation functions multiply their input vector with $\\mathbf{W}^\\top$ and $\\mathbf{W}$, respectively."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "* In contrast to the regular convolution that reduces input elements via the kernel, the transposed convolution broadcasts input elements via the kernel, thereby producing an output that is larger than the input.\n",
    "* If we feed $\\mathsf{X}$ into a convolutional layer $f$ to output $\\mathsf{Y}=f(\\mathsf{X})$ and create a transposed convolutional layer $g$ with the same hyperparameters as $f$ except for the number of output channels being the number of channels in $\\mathsf{X}$, then $g(Y)$ will have the same shape as $\\mathsf{X}$.\n",
    "* We can implement convolutions using matrix multiplications. The transposed convolutional layer can just exchange the forward propagation function and the backpropagation function of the convolutional layer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}